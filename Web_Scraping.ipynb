{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPfCPJJZdxuwThSMWxP43Sb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/umeedesehar/Python/blob/main/Web_Scraping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Web Scraping**\n",
        "## **NOTE**: To best learn web scraping see the labs downloaded from coursera\n",
        "There are two ways to scrape a website\n",
        "1. Through APIs\n",
        "2. Through BeautifulSoup"
      ],
      "metadata": {
        "id": "Q5wyLLnnHAuC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###For HTML web scraping you need two modules\n",
        "+ BeautifulSoup\n",
        "+ requests"
      ],
      "metadata": {
        "id": "kadv5nDv-sVV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Step 1**: First you need to install BeautifulSoup4 and request"
      ],
      "metadata": {
        "id": "XtVXFzajHHJi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install Beautifulsoup4\n",
        "pip install requests\n",
        "pip install html5lib"
      ],
      "metadata": {
        "id": "0O3DIDQ9HdrD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 2**: Now we need to import these modules"
      ],
      "metadata": {
        "id": "t-FTtGUwJMRf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n"
      ],
      "metadata": {
        "id": "E5XkFIdrIzFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 3**: Get the HTML by request.get methode"
      ],
      "metadata": {
        "id": "Qt1eGHEEKAnZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://en.wikipedia.org/wiki/Alergies' #paste your website link in qoutation\n",
        "req = requests.get(url)\n",
        "htmlcontent = req.content"
      ],
      "metadata": {
        "id": "RRqPwlE8KW-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "soup1 = BeautifulSoup(req, \"html5lib\")"
      ],
      "metadata": {
        "id": "5tS1xD4egNKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 4**: Now we parse the HTML object and request the content"
      ],
      "metadata": {
        "id": "rwiy8n2pKB5I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "soup = BeautifulSoup(htmlcontent,\"html.parser\")\n",
        "print(soup) #it will show the HTML content in structured format"
      ],
      "metadata": {
        "id": "hzpDpwycNC3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(soup.prettify()) #will show the content in a beautiful way pretfied way"
      ],
      "metadata": {
        "id": "ZH_WwiPrOA_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### To get the title of the website"
      ],
      "metadata": {
        "id": "470G-3A-KCHA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res = soup.title\n",
        "print(res.prettify())"
      ],
      "metadata": {
        "id": "MGAjcbFOOqHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### To get just the title without tags"
      ],
      "metadata": {
        "id": "4FXSVLvWKCM0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(res.get_text())"
      ],
      "metadata": {
        "id": "oQ0jarbfPH05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### To get the content"
      ],
      "metadata": {
        "id": "asz6jFSDPFEU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = BeautifulSoup(req.text, 'html')\n",
        "print(text)"
      ],
      "metadata": {
        "id": "9iOr42RCmzEt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### To get the Paragraphs"
      ],
      "metadata": {
        "id": "aYVaRQ4-0DXu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "paras = soup.find_all('p')\n",
        "# print(soup.find('p')) to get the first para\n",
        "print(paras)\n",
        "\n"
      ],
      "metadata": {
        "id": "kmoz7nSH0JbY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### To get all the anchor tags"
      ],
      "metadata": {
        "id": "9PK2cesu0i4w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "anchor = soup.find_all('a')\n",
        "print(anchor)"
      ],
      "metadata": {
        "id": "LZ9jehqW0m-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get all the links on the page"
      ],
      "metadata": {
        "id": "MzS4PdCv2oAy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for link in anchor:\n",
        "  print(link.get('href'))"
      ],
      "metadata": {
        "id": "W0GSH02p2r6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Get classes of any element"
      ],
      "metadata": {
        "id": "gdQGUDVE1YsT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(soup.find('p')['class'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wddDuVh1biS",
        "outputId": "d0e3a547-6cd8-4cd2-a89d-8d3c5b62b604"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['mw-empty-elt']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### To get the text from the tags/soup"
      ],
      "metadata": {
        "id": "ubDLTsvx2H9u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(soup.find('p').get_text())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6R-zdM-r2Num",
        "outputId": "2a261ae3-80a9-46eb-878d-26eea0f741c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 2**: To get the table if there is any\n",
        "1. Go the the website and inspects its elements\n",
        "2. Press Ctrl+shift+c to inpect the site by elements\n",
        "2. In the html table hover your arrow to find when the desired table highlights\n",
        "3. Copy the link and paste it in the cell\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2xDuCyrpPFKl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 2**: Now we need to import these modules"
      ],
      "metadata": {
        "id": "-mHnJGDSPFPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "<table class= \"wikitable\" style=\"width:70%\"; float:center; font-size:90%; margin-left:15px\"> ==$0"
      ],
      "metadata": {
        "id": "GzPXADeZuIZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "soup.find_all('table')[2]"
      ],
      "metadata": {
        "id": "3c1t2ndD5GHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "req.status_code"
      ],
      "metadata": {
        "id": "WOmH5JFwiqWm",
        "outputId": "ca043e39-6db2-4582-be97-9064c70f6d00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Few more codes"
      ],
      "metadata": {
        "id": "cdm8KQBb52iS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = soup.title #to get the title\n",
        "type(a) #to see the type\n",
        "tag_child = soup.h3 #to get the first <h3> tag\n",
        "c = tag_child.b # to get the first <b> tag that is the child of <h3> tag stored in tag_object\n",
        "parent_tag = tag_child.parent #to get the parent tag of the <b> tag stored in the variable tag_child\n",
        "sibling_1=tag_object.next_sibling #sibling is the paragraph paragraph element\n",
        "sibling_2=sibling_1.next_sibling\n",
        "sibling_3 = sibling_2. next_sibling\n"
      ],
      "metadata": {
        "id": "Z_FHNXcAJhwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### HTML Attributes\n",
        "If the tag has attributes, the tag id=\"boldest\" has an attribute id whose value is boldest. You can access a tag’s attributes by treating the tag like a dictionary:"
      ],
      "metadata": {
        "id": "OC-f6nwWMozy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tag_child['id'] #or\n",
        "tag_child.get('id')\n",
        "tag_child.attrs #You can access that dictionary directly as attrs:\n"
      ],
      "metadata": {
        "id": "dqESQF5OMuPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Findall\n",
        "The find_all() method looks through a tag’s descendants and retrieves all descendants that match your filters.\n",
        "\n",
        "The Method signature for find_all(name, attrs, recursive, string, limit, **kwargs)"
      ],
      "metadata": {
        "id": "3DTe8K39NSwt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "table_rows=table_bs.find_all('tr') # to get all the table rows\n",
        "first_row =table_rows[0] # to get the first row\n",
        "first_row.td # to get the child\n",
        "table_bs.find_all(id=\"flight\") #it will find id attribut equals to flight\n"
      ],
      "metadata": {
        "id": "xcoAACyuNabb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# scrape all links\n",
        "for link in soup.find_all('a',href=True):  # in html anchor/link is represented by the tag <a>\n",
        "\n",
        "    print(link.get('href'))"
      ],
      "metadata": {
        "id": "F9RnXRSDRpGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#scrape all images\n",
        "for link in soup.find_all('a',href=True):  # in html anchor/link is represented by the tag <a>\n",
        "\n",
        "    print(link.get('href'))"
      ],
      "metadata": {
        "id": "VSoy66QBRtOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### To get a table"
      ],
      "metadata": {
        "id": "-euY2_UOSHtz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#find a html table in the web page\n",
        "table = soup.find('table') # in html table is represented by the tag <table>"
      ],
      "metadata": {
        "id": "ifnDve1BSKCI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get all rows from the table\n",
        "for row in table.find_all('tr'): # in html table row is represented by the tag <tr>\n",
        "    # Get all columns in each row.\n",
        "    cols = row.find_all('td') # in html a column is represented by the tag <td>\n",
        "    color_name = cols[2].string # store the value in column 3 as color_name\n",
        "    color_code = cols[3].string # store the value in column 4 as color_code\n",
        "    print(\"{}--->{}\".format(color_name,color_code))"
      ],
      "metadata": {
        "id": "Q4F1MosTSMii"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}